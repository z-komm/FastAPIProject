# ğŸ› ï¸ KI-Inhouse-Chat-System (RAG + Ollama)

## Projektbeschreibung

Dieses System stellt ein webbasiertes, mehrbenutzerfÃ¤higes Chatinterface bereit, das mit einem lokalen Ollama-Modell arbeitet und per RAG (Retrieval-Augmented Generation) unternehmensinterne Dokumente durchsucht. Sessions werden gespeichert, inklusive KI-generierter Zusammenfassungen. Quellenangaben sind in jeder Antwort enthalten.

---

## Features

- âœ… Ollama-Integration (lokal)
- âœ… Dokumentenpool (RAG, sqlite-vec)
- âœ… System- & Master-Prompt (zentral steuerbar)
- âœ… Multiuser-Chat via WebSocket
- âœ… Streaming-Antworten (wie ChatGPT)
- âœ… Session-Management inkl. Zusammenfassungen
- âœ… Quellenangabe + Verlinkung
- âœ… Intranet-fÃ¤higes Deployment (Docker)

---

## Verzeichnisstruktur

```plaintext
backend/           # FastAPI + RAG Backend
frontend/          # React Frontend (geplant)
data/              # Dokumente und SQLite-Datenbank
docker-compose.yml
README.md
